---
title: "Week 8 - Homework"
author: "Saurav Prem Kaushik Chetry"
date: ''
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---



```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")
```

## Exercise 1 (Writing Functions)

**(a)** Write a function named `diagnostics` that takes as input the arguments:

- `model`, an object of class `lm()`, that is a model fit via `lm()`
- `pcol`, for controlling point colors in plots, with a default value of `grey`
- `lcol`, for controlling line colors in plots, with a default value of `dodgerblue`
- `alpha`, the significance level of any test that will be performed inside the function, with a default value of `0.05`
- `plotit`, a logical value for controlling display of plots with default value `TRUE`
- `testit`, a logical value for controlling outputting the results of tests with default value `TRUE`

The function should output:

- A list with two elements when `testit` is `TRUE`:
    - `p_val`, the p-value for the Shapiro-Wilk test for assessing normality
    - `decision`, the decision made when performing the Shapiro-Wilk test using the `alpha` value input to the function. "Reject" if the null hypothesis is rejected, otherwise "Fail to Reject."
- Two plots, side-by-side, when `plotit` is `TRUE`:
    - A fitted versus residuals plot that adds a horizontal line at $y = 0$, and labels the $x$-axis "Fitted" and the $y$-axis "Residuals." The points and line should be colored according to the input arguments. Give the plot a title. 
    - A Normal Q-Q plot of the residuals that adds the appropriate line using `qqline()`. The points and line should be colored according to the input arguments. Be sure the plot has a title. 

Consider using this function to help with the remainder of the assignment as well.

```{r}
diagnostics = function(model, pcol = "grey", lcol = "dodgerblue", alpha = 0.05, plotit = TRUE, testit = TRUE){

  if(plotit == TRUE){
    par(mfrow = c(1, 2))
    
    plot(fitted(model), resid(model), col = pcol, pch = 20,
    xlab = "Fitted", ylab = "Residuals", main = "Fitted Vs Residuals")
    abline(h = 0, col = lcol, lwd = 2)
    
    qqnorm(resid(model), main = "Normal Q-Q Plot, model", col = pcol)
    qqline(resid(model), col = lcol, lwd = 2)
  }
  
  if(testit == TRUE){
    p_val = shapiro.test(resid(model))$p.value
    decision = ifelse(p_val < alpha, "Reject", "Fail to Reject")
    list(p_val = p_val, decision = decision)
    }
  
}


```


**(b)** Run the following code.

```{r}
set.seed(420)

data_1 = data.frame(x = runif(n = 30, min = 0, max = 10),
                    y = rep(x = 0, times = 30))
data_1$y = with(data_1, 2 + 1 * x + rexp(n = 30))
fit_1 = lm(y ~ x, data = data_1)

data_2 = data.frame(x = runif(n = 20, min = 0, max = 10),
                    y = rep(x = 0, times = 20))
data_2$y = with(data_2, 5 + 2 * x + rnorm(n = 20))
fit_2 = lm(y ~ x, data = data_2)

data_3 = data.frame(x = runif(n = 40, min = 0, max = 10),
                    y = rep(x = 0, times = 40))
data_3$y = with(data_3, 2 + 1 * x + rnorm(n = 40, sd = x))
fit_3 = lm(y ~ x, data = data_3)
```

```{r }
diagnostics(fit_1, plotit = FALSE)$p_val
diagnostics(fit_2, plotit = FALSE)$decision
diagnostics(fit_1, testit = FALSE, pcol = "black", lcol = "black")
diagnostics(fit_2, testit = FALSE, pcol = "grey", lcol = "green")
diagnostics(fit_3)
```

***

## Exercise 2 (Prostate Cancer Data)

For this exercise, we will use the `prostate` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?prostate` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
#install.packages("faraway")
library(faraway)
?prostate
```

**(a)** Fit an additive multiple regression model with `lpsa` as the response and the remaining variables in the `prostate` dataset as predictors. Report the $R^2$ value for this model.
```{r}
w08_m2a = lm(lpsa ~ ., data = prostate)
summary(w08_m2a)$r.squared
```
The $R^2$ for given model is <tt>`r summary(w08_m2a)$r.squared`</tt>

**(b)** Check the constant variance assumption for this model. Do you feel it has been violated? Justify your answer.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
diagnostics(w08_m2a, testit = FALSE, pcol = 'darkgrey', lcol = 'darkorange')
library(lmtest)
bptest(w08_m2a)
```
The Fitted Vs Residuals plot does not show any particular pattern about the residual distribution. This indicates a constant variance of residuals. To double check this Breusch-Pagan test is performed on the fitted model and the BP test gives a $p-value =$ <tt>`bptest(w08_m2a)$p.value`</tt>. The hight $p-value$ indicates a Fail to Reject null hypothesis. This confirms the finding from the plot that there is a constant variance of residuals.

**(c)** Check the normality assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
diagnostics(w08_m2a, pcol = 'darkgrey', lcol = 'darkorange')
```
Running the Shapiro-Wilk test on the model, we observe a high $p-value$ = <tt>`r diagnostics(w08_m2a)$p_val`</tt>.
We fail to reject the null hypothesis, therefore the normality assumption is true, i.e. data were sampled from a normal distribution.

**(d)** Check for any high leverage observations. Report any observations you determine to have high leverage.

Hatvalues greater than twice the mean of all hat values identify the observations with high leverage. They can influence the model. These observations are:

```{r}
(high_leverage = hatvalues(w08_m2a)[hatvalues(w08_m2a) > 2 * mean(hatvalues(w08_m2a))])
```


**(e)** Check for any influential observations. Report any observations you determine to be influential.

Infuential observations from cooks distance calculation for the given model are:
```{r}
(inf_obs = cooks.distance(w08_m2a)[cooks.distance(w08_m2a) > 4 / length(cooks.distance(w08_m2a))])

```


**(f)** Refit the additive multiple regression model without any points you identified as influential. Compare the coefficients of this fitted model to the previously fitted model.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
prostate_minus_inf = prostate[-c(32,39,47,69,95,96,97),]
w08_m2a_minus = lm(lpsa ~ ., data = prostate_minus_inf)
compare_coef = data.frame("previous model" = coef(w08_m2a),"new model" = coef(w08_m2a_minus))
#compare_coef
library(knitr)
kable(compare_coef, digits = 6)
```
There are some significant coef changes between the previous model and new fitted model.

**(g)** Create a data frame that stores the observations that were "removed" because they were influential. Use the two models you have fit to make predictions with these observations. Comment on the difference between these two sets of predictions.

```{r}
removed = prostate[c(32,39,47,69,95,96,97),]

```
Predicted lpsa of the removed influential obs by old model are:
```{r}
predict(w08_m2a, newdata = removed)
```


Predicted lpsa of the removed influential obs by new model are:
```{r}
predict(w08_m2a_minus, newdata = removed)
```

RMSE old model:
```{r}
sqrt(mean(resid(w08_m2a) ^ 2))
```
RMSE new model:
```{r}
sqrt(mean(resid(w08_m2a_minus) ^ 2))
```

It is observed that the new model( fitted without the influential obs), i.e.,w08_m2a_minus, predicts higher lpsa values for the removed observations, compared to the predicted lpsa values by the older model, i.e. w08_m2a.

RMSE of the old model is:<tt>`r sqrt(mean(resid(w08_m2a) ^ 2))`</tt>.
RMSE of the new model is:<tt>`r sqrt(mean(resid(w08_m2a_minus) ^ 2))`</tt>.

As RMSE of the new model is lower, the predictions about the removed observations are correct. As we can see higher predicted lmsa for the removed objects from the new model, this shows the significant influence of the removed observations to the original model.

***

## Exercise 3 (Why Bother?)

**Why** do we care about violations of assumptions? One key reason is that the distributions of the parameter esimators that we have used are all reliant on these assumptions. When the assumptions are violated, the distributional results are not correct, so our tests are garbage. **Garbage In, Garbage Out!**

Consider the following setup that we will use for the remainder of the exercise. We choose a sample size of 50.

```{r}
n = 50
set.seed(420)
x_1 = runif(n, 0, 5)
x_2 = runif(n, -2, 2)
```

Consider the model,

\[
Y = 4 + 1 x_1 + 0 x_2 + \epsilon.
\]

That is,

- $\beta_0$ = 4
- $\beta_1$ = 1
- $\beta_2$ = 0

We now simulate `y_1` in a manner that does **not** violate any assumptions, which we will verify. In this case $\epsilon \sim N(0, 1).$

```{r}
set.seed(1)
y_1 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = 1)
fit_1 = lm(y_1 ~ x_1 + x_2)
bptest(fit_1)
```

Then, we simulate `y_2` in a manner that **does** violate assumptions, which we again verify. In this case $\epsilon \sim N(0, \sigma = |x_2|).$

```{r}
set.seed(1)
y_2 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = abs(x_2))
fit_2 = lm(y_2 ~ x_1 + x_2)
summary(fit_2)$coefficients[3,4]
bptest(fit_2)
```

**(a)** Use the following code after changing `birthday` to your birthday.

```{r}
num_sims = 2500
p_val_1 = rep(0, num_sims)
p_val_2 = rep(0, num_sims)
birthday = 19850208
set.seed(birthday)

```

Repeat the above process of generating `y_1` and `y_2` as defined above, and fit models with each as the response `2500` times. Each time, store the p-value for testing,

\[
\beta_2 = 0,
\]

using both models, in the appropriate variables defined above. (You do not need to use a data frame as we have in the past. Although, feel free to modify the code to instead use a data frame.)



**(b)** What proportion of the `p_val_1` values is less than 0.01? Less than 0.05? Less than 0.10? What proportion of the `p_val_2` values is less than 0.01? Less than 0.05? Less than 0.10? Arrange your results in a table. Briefly explain these results.

```{r message=FALSE, warning=FALSE}
for( i in 1: num_sims){
  
y_1 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = 1)
fit_1 = lm(y_1 ~ x_1 + x_2)
#bptest(fit_1)
p_val_1[i] = summary(fit_1)$coefficients[3,4]
  
y_2 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = abs(x_2))       
fit_2 = lm(y_2 ~ x_1 + x_2)
#bptest(fit_2)  
p_val_2[i] = summary(fit_2)$coefficients[3,4]
  
}

result = data.frame("alpha" = c(0.01, 0.05, 0.10),
                    "fit_1" = c(mean(p_val_1 < 0.01), mean(p_val_1 < 0.05), mean(p_val_1 < 0.10)),
                    "fit_2" = c(mean(p_val_2 < 0.01), mean(p_val_2 < 0.05), mean(p_val_2 < 0.10)))

library(knitr)
kable(result, digits = 5)
```

fit_1 is the model where assumptions are valid, fit_2 is the model where assumptions are violated.

Based on the 2500 simulations, the $p-value$ for testing $\beta_2\ = 0$ from fit_1 is constantly less than or equal to each significance level chosen. Therefore null-hypothesis is rejected for fit_1, which means $\beta_2$ is statistically significant.

The $p-value$ for testing $\beta_2\ = 0$ from fit_2 is constantly higher than the significance level chosen. Therefore null-hypothesis fails to be rejected for fit_2, which means $\beta_2$ is statistically non-significant. I think we found a non-significant $\beta$ parameter of the model because of violated assumptions( constant variance in fit_2)



## Exercise 4 (Corrosion Data)

For this exercise, we will use the `corrosion` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?corrosion` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
?corrosion
```

**(a)** Fit a simple linear regression with `loss` as the response and `Fe` as the predictor. Plot a scatterplot and add the fitted line. Check the assumptions of this model.
```{r}
w08_m4a = lm(loss ~ Fe, data = corrosion)
plot(loss ~ Fe, data = corrosion, col = "darkgrey", cex = 2, main = 'Weight loss vs Iron Content')
abline(w08_m4a, col = "dodgerblue", lwd = 2)
diagnostics(w08_m4a, testit = TRUE)



```
The scatter plot with the fitted line looks to estimate the most observations correctly. 

The fitted vs residuals plot does not show any visible distribution pattern, suggesting a constant variance, will confirm using BP test. The Q-Q line looks is not conclusive, we need to run the Shakiro-Wilk test.

From BP-test, the $p-value$ is <tt>`r bptest(w08_m4a)$p.value`</tt>. With this high $p-value$ we fail to reject the null hypothesis, that means - the errors have constant variance about the true model, confirming the plot observastion.

From Shakiro- Wilk test, the $p-value$ is <tt>`r diagnostics(w08_m4a, plotit = FALSE)$p_val`</tt>. With this high $p-value$ we fail to reject the null hypothesis, that means - there is a high probability the data could have been sampled from a normal distribution.


**(b)** Fit higher order polynomial models of degree 2, 3, and 4. For each, plot a fitted versus residuals plot and comment on the constant variance assumption. Based on those plots, which of these three models do you think are acceptable? Use a statistical test(s) to compare the models you just chose. Based on the test, which is preferred? Check the normality assumption of this model. Identify any influential observations of this model.

```{r}
w08_m4a_d2 = lm(loss ~ Fe + I(Fe^2), data = corrosion)
w08_m4a_d3 = lm(loss ~ Fe + I(Fe^2) + I(Fe^3), data = corrosion)
w08_m4a_d4 = lm(loss ~ Fe + I(Fe^2) + I(Fe^3) + I(Fe^4), data = corrosion)

diagnostics(w08_m4a_d2, testit = FALSE)
diagnostics(w08_m4a_d3, testit = FALSE)
diagnostics(w08_m4a_d4, testit = FALSE)

bptest(w08_m4a_d2)$p.value
bptest(w08_m4a_d3)$p.value
bptest(w08_m4a_d4)$p.value
```
BP test of all higher order polynomial models give a high $p-value$. Suggesting no violation of constant variance assumption in any of these models.

Comparing the fitted vs residuals plot for models of degree 2, 3, and 4, I think models with degree 3 and degree 4 are more acceptable. Their plots shows a uniform residual range and also there is no visible pattern, suggesting the most constant variance of residuals. Model with degree 2 is not accepted for a non-uniform residual range in the plot. Between model with degree 3 and degree 4, I prefer model 3. Let's compare them using anova test:

```{r}
anova(w08_m4a_d3, w08_m4a_d4)

```

Since the $p-value$ of the anova test is high<tt>`anova(w08_m4a_d3, w08_m4a_d4)[2,6]`</tt>, I am more confident now in preferring model with degree 3. 

From the BP-test for this model, the $p-value$ is <tt>`r bptest(w08_m4a_d3)$p.value`</tt>. This model does not violate the constant variance assumption. 

From the Shapiro-Wilk normality test, the $p-value$ is <tt>`r diagnostics(w08_m4a_d3, plotit = FALSE)$p_val`</tt>. This high $p-value$ suggests normality assumption is not violated.

Checking for influential observation for this model, we find that there are none.

```{r}
cooks.distance(w08_m4a_d3)[cooks.distance(w08_m4a_d3) > 4/length(cooks.distance(w08_m4a_d3))]
```

Influential observations for degree 3 model are: <tt>`r cooks.distance(w08_m4a_d3)[cooks.distance(w08_m4a_d3) > 4/length(cooks.distance(w08_m4a_d3))]`</tt>. There are no infuential observations.


***

## Exercise 5 (Diamonds)

The data set `diamonds` from the `ggplot2` package contains prices and characteristics of 54,000 diamonds. For this exercise, use `price` as the response variable $y$, and `carat` as the predictor $x$. Use `?diamonds` to learn more.

```{r, message = FALSE, warning = FALSE}
library(ggplot2)
?diamonds

```

**(a)** Fit a linear model with `price` as the response variable $y$, and `carat` as the predictor $x$. Return the summary information of this model.

```{r}
w08_m5a = lm(price ~ carat, data = diamonds)
summary(w08_m5a)
```

From the summary, the $p-value$ is very small( reject null hypothesis for carat), suggesting high significance of predictor(carat) in determining the response(price)

**(b)** Plot a scatterplot of price versus carat and add the line for the fitted model in part **(a)**. Using a fitted versus residuals plot and/or a Q-Q plot, comment on the diagnostics. 

```{r}
#w08_m5a = lm(y ~ x, data = diamonds)
plot(price ~ carat, data = diamonds, col = "darkgrey", main = 'Diamond Price vs Carat', pch = 20, cex = 1)
abline(w08_m5a, col = "darkorange", lwd = 2)

```
```{r}
diagnostics(w08_m5a, testit = FALSE, plotit = TRUE)
```

Fitted Vs Residuals plot shows violation of constat variance assumption. There is a decreasing pattern of the residual distribution.

Q-Q plot also shows violation of the normality assumption.

**(c)** Seeing as the price stretches over several orders of magnitude, it seems reasonable to try a log transformation of the response. Fit a model with a logged response, plot a scatterplot of log-price versus carat and add the line for the fitted model, then use a fitted versus residuals plot and/or a Q-Q plot to comment on the diagnostics of the model.

```{r}
qplot(price, data = diamonds, bins = 30)
```
```{r}
w08_m5a_log = lm(log(price) ~ carat, data = diamonds)
summary(w08_m5a_log)
plot(log(price) ~ carat, data = diamonds, col = "darkgrey", main = 'Diamond Price vs Carat', pch = 20, cex = 1)
abline(w08_m5a_log, col = "darkorange", lwd = 2)
diagnostics(w08_m5a_log, testit = FALSE)
```

Small $p-value$ from the summary of the log model shows significant relationship of carat to log(price). 
Fitted Vs Residuals does not show to conform constant variance.
Q-Q plot does not show to conform normal distribution.

**(d)** Try adding log transformation of the predictor. Fit a model with a logged response and logged predictor, plot a scatterplot of log-price versus log-carat and add the line for the fitted model, then use a fitted versus residuals plot and/or a Q-Q plot to comment on the diagnostics of the model.

```{r}
w08_m5a_log_rp = lm(log(price) ~ log(carat), data = diamonds)
summary(w08_m5a_log_rp)
plot(log(price) ~ log(carat), data = diamonds, col = "darkgrey", main = 'Diamond Price vs Carat', pch = 20, cex = 1)
abline(w08_m5a_log_rp, col = "darkorange", lwd = 2)
diagnostics(w08_m5a_log_rp, testit = FALSE)
```

The small $p-value$ from summary of this model shows significant relationship between log(carat) and log(price).
Fitted Vs Residual plot shows conformity with constant variance assumption.
Q-Q plot shows conformity with normal distribution assumption.

**(e)** Use the model from part **(d)** to predict the price (in dollars) of a 3-carat diamond. Construct a 99% prediction interval for the price (in dollars).

```{r}
predicted = exp(predict(w08_m5a_log_rp, newdata = data.frame(carat = 3), interval = 'prediction', level = 0.99))
#predicted[3]
```

3 carat diamond will cost <tt>`r predicted[1]`</tt> $USD.
Lower bound of the 99% PI is: <tt>`r predicted[2]`</tt> $USD.
Upper bound of the 99% PI is: <tt>`r predicted[3]`</tt> $USD.

